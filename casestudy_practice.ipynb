{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce95c57",
   "metadata": {},
   "source": [
    "# Codealong Notebook\n",
    "\n",
    "Use this notebook as your \"scratch pad\" as you go through the course contents. Feel free to copy any example code and tweak it to get a better understanding of how it works!\n",
    "\n",
    "Use the **+** button or `Insert` menu to add additional code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da1ad2",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72084745",
   "metadata": {},
   "source": [
    "### Loading the Data with `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "params = {\n",
    "    \"action\": \"query\", \n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": \"2022\",\n",
    "    \"explaintext\": 1,\n",
    "    \"formatversion\": 2,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
    "response_dict = resp.json()\n",
    "response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a86103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load page text into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4011316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff2773",
   "metadata": {},
   "source": [
    "### Creating an Embeddings Index with `openai.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5405d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME =\"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb432822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic example code\n",
    "response = openai.Embedding.create(\n",
    "    input=df[\"text\"].tolist(),\n",
    "    model=EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edacca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928622c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c521e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f77040",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response[\"data\"][0][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [data[\"embedding\"] for data in response[\"data\"]]\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embeddings\"] = embeddings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e736786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b7331",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152dad6",
   "metadata": {},
   "source": [
    "### Finding Relevant Data with Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did Russia invade Ukraine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8730ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME =\"text-embedding-ada-002\"\n",
    "question_embedding = get_embedding(question,engine= EMBEDDING_MODEL_NAME)\n",
    "question_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec62d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = distances_from_embeddings(\n",
    "    question_embedding,\n",
    "    df[\"embeddings\"].tolist(),\n",
    "    distance_metric=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"distances\"] = distances\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"distances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278234ca",
   "metadata": {},
   "source": [
    "## One Way of Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca468725",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_shortest = df.iloc[0][\"distances\"]\n",
    "current_shortest_index=0\n",
    "current_shortest,current_shortest_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,distance in enumerate(df[\"distances\"].values):\n",
    "    if distance < current_shortest:\n",
    "        current_shortest = distance\n",
    "        current_shortest_index= index\n",
    "\n",
    "current_shortest,current_shortest_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[34][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad09db2",
   "metadata": {},
   "source": [
    "## Another Way of Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"distances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c563ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[55][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"distances\").to_csv(\"distances_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699486f6",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3716d6",
   "metadata": {},
   "source": [
    "### Tokenizing with `tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0888179",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"This is a question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did Russia invade Ukraine?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.encode(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d6d19",
   "metadata": {},
   "source": [
    "### Composing a Custom Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c35486",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\"\n",
    "Answer the question based on the context below and if the question can't be answered on the context , say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "{}\n",
    "\n",
    "--------\n",
    "Question :{}\n",
    "Answer \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did Russia invade Ukraine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c482c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template.format(\"context\", question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_count = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e42a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f86b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8848c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.encode(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(question))\n",
    "current_token_count"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bfe8c0b",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1db2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=[]\n",
    "for text in df[\"text\"].values:\n",
    "    text_token_count = len(tokenizer.encode(text))\n",
    "    current_token_count += text_token_count\n",
    "    \n",
    "    if current_token_count <= max_token_count:\n",
    "        context.append(text)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f885a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc157ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bd5b1",
   "metadata": {},
   "source": [
    "### Another Way !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "\n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = create_prompt(question, df, max_token_count)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8f5dd",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a549a",
   "metadata": {},
   "source": [
    "### Getting a Custom Q&A Response with `openai.Completion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626eb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df71b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question))[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukraine_prompt = \"\"\"\n",
    "Question: \"When did Russia invade Ukraine?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_ukraine_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=ukraine_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_ukraine_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_prompt = \"\"\"\n",
    "Question: \"Who owns Twitter?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_twitter_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=twitter_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_twitter_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2515574",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "\n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = answer_question(question, df, max_prompt_tokens=1800, max_answer_tokens=150)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df815aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
